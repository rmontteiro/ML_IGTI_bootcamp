{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Desafio_mod4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNeqRzPShOu/kpVX0bex1uy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rmontteiro/ML_IGTI_bootcamp/blob/master/Desafio2_mod4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahqzyvWsL1kI"
      },
      "source": [
        "import tensorflow as tf\n",
        "AUTOTUNE= tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5miwzjV4MC50"
      },
      "source": [
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i6DHb1nMWNm"
      },
      "source": [
        "tf__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBkRABxBMZ68"
      },
      "source": [
        "Antes de iniciar qualquer treinamento, você precisará carregar o conjunto de imagens\n",
        "para ensinar à rede as novas classes que deseja reconhecer. Vamos usar um arquivo\n",
        "de fotos de flores licenciadas da creative-commons do Google.\n",
        "O conjunto de dados usado neste exemplo é distribuído como diretórios de imagens,\n",
        "com uma classe de imagem por diretório.\n",
        "Se quiser conferir o banco de imagens, baixe as fotos de:\n",
        "http://download.tensorflow.org/example_images/flower_photos.tgz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvUmmKLaMagt"
      },
      "source": [
        "import pathlib\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97fa5HskMdAG"
      },
      "source": [
        "data_dir=tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "                                 fname='flower_photos', untar=True)\n",
        "data_dir=pathlib.path(data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mG9dLF2Og1B"
      },
      "source": [
        "Após o download (218MB), você deve ter uma cópia das fotos da flor disponível.\n",
        "O diretório contém alguns subdiretórios, um por classe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwcMwOlyOemm"
      },
      "source": [
        "image_count=len(list(data_dir.glob('*/*.jpg')))\n",
        "image_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5N9MReoOytz"
      },
      "source": [
        "O count retornará o número de imagens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o4wowNROvZ8"
      },
      "source": [
        "CLASS_NAMES=np.array([item.name for item in data_dir.glob('*') if item.name!='LICENSE.txt'])\n",
        "CLASS_NAMES"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AY4ETGNPOKC"
      },
      "source": [
        "Cada diretório contém imagens desse tipo de flor. Aqui estão algumas rosas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqYBrUm8PO-I"
      },
      "source": [
        "roses=list(data_dir.glob('roses/*'))\n",
        "\n",
        "for image_path in roses[:3]:\n",
        "  display.display(Image.open(str(image_path)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3a8vTl0P2Is"
      },
      "source": [
        "#incorporando o desafio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbP_K5PtP551"
      },
      "source": [
        "import itertools\n",
        "import os\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oYEgUBMQDL3"
      },
      "source": [
        "module_selection = (\"mobilenet_v2_100_224\", 224) \n",
        "handle_base, pixels = module_selection\n",
        "MODULE_HANDLE =\"https://tfhub.dev/google/imagenet/{}/feature_vector/4\".format(handle_base)\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "print(\"Using {} with input size {}\".format(MODULE_HANDLE, IMAGE_SIZE))\n",
        "\n",
        "BATCH_SIZE = 32 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMTOMYxMQFi1"
      },
      "source": [
        "data_dir = tf.keras.utils.get_file(\n",
        "    'flower_photos',\n",
        "    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "    untar=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxEX1anEQJB5"
      },
      "source": [
        "datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n",
        "dataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n",
        "                   interpolation=\"bilinear\")\n",
        "\n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    **datagen_kwargs)\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    data_dir, subset=\"validation\", shuffle=False, **dataflow_kwargs)\n",
        "\n",
        "do_data_augmentation = False \n",
        "if do_data_augmentation:\n",
        "  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "      rotation_range=40,\n",
        "      horizontal_flip=True,\n",
        "      width_shift_range=0.2, height_shift_range=0.2,\n",
        "      shear_range=0.2, zoom_range=0.2,\n",
        "      **datagen_kwargs)\n",
        "else:\n",
        "  train_datagen = valid_datagen\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir, subset=\"training\", shuffle=True, **dataflow_kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxn8VHg1QNXh"
      },
      "source": [
        "Definindo o modelo\n",
        "Basta colocar um classificador linear no topo do feature_extractor_layer com o módulo Hub.\n",
        "\n",
        "Para velocidade, começamos com um feature_extractor_layer não treinável, mas você também pode ativar o ajuste fino para maior precisão."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYIlREU-QN_V"
      },
      "source": [
        "do_fine_tuning = False "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXAI0-4mQPtA"
      },
      "source": [
        "print(\"Building model with\", MODULE_HANDLE)\n",
        "model = tf.keras.Sequential([\n",
        "    # Explicitly define the input shape so the model can be properly\n",
        "    # loaded by the TFLiteConverter\n",
        "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
        "    hub.KerasLayer(MODULE_HANDLE, trainable=do_fine_tuning),\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(train_generator.num_classes,\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
        "])\n",
        "model.build((None,)+IMAGE_SIZE+(3,))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge188YBQQUjT"
      },
      "source": [
        "Treinando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSBVJe5qQVBl"
      },
      "source": [
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9), \n",
        "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "validation_steps = valid_generator.samples // valid_generator.batch_size\n",
        "hist = model.fit(\n",
        "    train_generator,\n",
        "    epochs=5, steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=validation_steps).history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm-MRG0nQZr1"
      },
      "source": [
        "plt.figure()\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(hist[\"loss\"])\n",
        "plt.plot(hist[\"val_loss\"])\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(hist[\"accuracy\"])\n",
        "plt.plot(hist[\"val_accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7e_WNW4QbtK"
      },
      "source": [
        "Experimente o modelo em uma imagem dos dados de validação:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8UiSd9eQcYJ"
      },
      "source": [
        "def get_class_string_from_index(index):\n",
        "   for class_string, class_index in valid_generator.class_indices.items():\n",
        "      if class_index == index:\n",
        "         return class_string\n",
        "\n",
        "x, y = next(valid_generator)\n",
        "image = x[0, :, :, :]\n",
        "true_index = np.argmax(y[0])\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Expand the validation image to (1, 224, 224, 3) before predicting the label\n",
        "prediction_scores = model.predict(np.expand_dims(image, axis=0))\n",
        "predicted_index = np.argmax(prediction_scores)\n",
        "print(\"True label: \" + get_class_string_from_index(true_index))\n",
        "print(\"Predicted label: \" + get_class_string_from_index(predicted_index))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6kCy-uzQiO-"
      },
      "source": [
        "Finalmente, o modelo treinado pode ser salvo para implantação no TF Serving ou TF Lite (no celular) como segue."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3ORnWKyQitC"
      },
      "source": [
        "saved_model_path = \"/tmp/saved_flowers_model\"\n",
        "tf.saved_model.save(model, saved_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}